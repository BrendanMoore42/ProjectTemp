{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ranges for search years\n",
    "start_range = np.arange(1982, 2015, 2)\n",
    "end_range = np.arange(1983, 2016, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set empty list to hold tables\n",
    "df_list = []\n",
    "\n",
    "#loop over lotto tables\n",
    "for i, j in zip(start_range, end_range):\n",
    "    #read table\n",
    "    table = pd.read_html(f'http://www.lotto649stats.com/winning-numbers-{i}-{j}.html')\n",
    "    #create df and extract dates\n",
    "    df = pd.DataFrame(table[0])\n",
    "    df = df.iloc[4:,].iloc[:,:8]\n",
    "    #add each df to holding list\n",
    "    df_list.append(df)\n",
    "    \n",
    "#concat list together, drop NA's and rename Date column\n",
    "df_master = pd.concat(df_list)\n",
    "df_past = df_master.dropna(axis=0).rename(columns={0:'Date'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0   1   2   3   4   5   6   7\n",
      "4  September 15, 2018   3   4  18  24  32  36  19\n",
      "5  September 12, 2018  14  21  27  32  35  43  41\n",
      "6   September 8, 2018   8  10  31  41  46  47  45\n",
      "7   September 5, 2018   4   6  15  32  36  47  48\n",
      "8   September 1, 2018   8  12  15  34  37  44  45\n",
      "                 Date   1   2   3   4   5   6   7\n",
      "0  September 19, 2015  12  15  17  21  25  32  14\n",
      "1  September 23, 2015   7  13  19  35  42  44  46\n",
      "2  September 26, 2015   6  13  14  24  32  34  12\n",
      "3  September 30, 2015   1   6   8  13  21  26   3\n",
      "4     October 3, 2015   1   3  15  27  31  36  33\n"
     ]
    }
   ],
   "source": [
    "def get_current():\n",
    "    #returns current lotto results in dataframe\n",
    "    #grab table\n",
    "    table = pd.read_html('http://www.lotto649stats.com/recent_winning.html')\n",
    "    #extract just the information we want\n",
    "    df = pd.DataFrame(table[0])\n",
    "    df = df.iloc[4:,].iloc[:,:8]\n",
    "    print(df.head(5))\n",
    "    #reverse the order, replace column with date\n",
    "    df = df.iloc[::-1,:].reset_index().drop('index', axis=1)\n",
    "    df = df.dropna(axis=0).rename(columns={0:'Date'})\n",
    "    print(df.head(5))\n",
    "    #return df as a variable\n",
    "    return df\n",
    "\n",
    "#create df variable\n",
    "df_current = get_current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final dataframe with everything\n",
    "df_final = df_past.append(df_current, ignore_index=True)\n",
    "#create file in directory\n",
    "#df_final.to_csv('lotto_final_19_08_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create day number - Saturday = 0, Wednesday = 1\n",
    "df_final['temp_date'] = pd.to_datetime(df_final['Date'])\n",
    "df_final['day_rank'] = df_final['temp_date'].dt.day_name()\n",
    "df_final['day'] = np.where(df_final['day_rank'] == 'Saturday', 0, 1)\n",
    "df_final['day_of_month'] = df_final['temp_date'].apply(lambda x: x.day)\n",
    "df_final = df_final.drop(['Date', 'temp_date', 'day_rank'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2   3   4   5   6   7  day  day_of_month\n",
       "0  11  18  22  28  35  37  42    0            25\n",
       "1   7  13  23  32  33  45  36    0            18\n",
       "2   4   9  10  11  43  46   3    0            11\n",
       "3   6  17  24  36  38  46  29    0             4\n",
       "4   5  17  21  28  30  43  36    0            27"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25652674898>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a separate classification on each feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model #1\n",
    "# set features\n",
    "X = df_final.drop('day_of_month', axis=1)\n",
    "# set independent variable\n",
    "y = df_final['day_of_month']\n",
    "#split the training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized training accuracy is: 0.05384087791495199%\n",
      "The normalized test accuracy is: 0.03561643835616438%\n"
     ]
    }
   ],
   "source": [
    "#fit log model to data\n",
    "log_model = linear_model.LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "print('The normalized training accuracy is: {}%'.format(log_model.score(X_train, y_train)))\n",
    "print('The normalized test accuracy is: {}%'.format(log_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear Kernal SVM score: 3.5648994515539303\n",
      "rbf Kernal SVM score: 2.83363802559415\n",
      "sigmoid Kernal SVM score: 2.376599634369287\n"
     ]
    }
   ],
   "source": [
    "#test out different SVMs using the different kernals\n",
    "kerns = ['linear', 'rbf', 'sigmoid']\n",
    "for i in kerns:\n",
    "    #Kernel trick\n",
    "    svm = SVC(C=0.01, kernel='{}'.format(i))\n",
    "    svm.fit(X_train,y_train)\n",
    "    \n",
    "    #Get the score\n",
    "    print('{0} Kernal SVM score: {1}'.format(i, (100*svm.score(X_test,y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default RFR: 0.038\n"
     ]
    }
   ],
   "source": [
    "#testing out random forest  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Default RFR: %3.3f\" % (rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-358-b1ce90e978e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mxgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gradient Boost score: %3.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[1;32m--> 541\u001b[1;33m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    342\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[0;32m    343\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                                                                 feature_types)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    212\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[0;32m    213\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb =GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "print(\"Gradient Boost score: %3.3f\" % (100 * gb.score(X_test,y_test)))\n",
    "print(\"XG Boost score: %3.3f\"       % (100 * xgb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-359-dbca9bde4084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \"\"\"\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mtest_dmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"best_ntree_limit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    342\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[0;32m    343\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                                                                 feature_types)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    212\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[0;32m    213\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_train)\n",
    "stats.describe(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features. Got 8 features, expected 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-360-c9409c368f3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthree_means_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    869\u001b[0m             raise ValueError(\"Incorrect number of features. \"\n\u001b[0;32m    870\u001b[0m                              \"Got %d features, expected %d\" % (\n\u001b[1;32m--> 871\u001b[1;33m                                  n_features, expected_n_features))\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incorrect number of features. Got 8 features, expected 7"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "y_predict = three_means_model.predict(X_train)\n",
    "stats.describe(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0356489945155393"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "KNN_model = KNeighborsClassifier()\n",
    "SVM_model_one = SVC(kernel = 'linear', probability=True)\n",
    "SVM_model_two = SVC(kernel = 'rbf', probability=True)\n",
    "\n",
    "#Build the ensemble\n",
    "ensemble = VotingClassifier(estimators=[('KNN Model', KNN_model),\\\n",
    "                                        ('SVM Model Linear', SVM_model_one),\\\n",
    "                                        ('SVM Model RBF', SVM_model_two)],\\\n",
    "                                        voting=\"hard\",\\\n",
    "                                        weights = [1,1,1])\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "ensemble.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
